# USCIS Visa Bulletin RAG

A production-grade cloud-native **Retrieval-Augmented Generation (RAG)** system for querying USCIS Visa Bulletin PDFs using **Vertex AI (Gemini)**, **Chroma**, **Streamlit**, **Cloud Run**, and **GitHub Actions**.

ğŸ‘‰ **Live Demo:**  
https://uscis-visa-bulletin-rag-ui-947807269152.us-central1.run.app/

ğŸ‘‰ Demo URL is provided for convenience; availability depends on cloud billing and quotas.

## ğŸš€ What This Project Does

- ğŸ“„ **Automatically downloads** monthly USCIS Visa Bulletin PDFs
- ğŸ§  **Parses & chunks documents hierarchically** (sections + tables + rows)
- ğŸ” **Indexes structured chunks into Chroma** with rich metadata
- â˜ï¸ **Persists embeddings to Google Cloud Storage (GCS)**
- ğŸ’¬ **Answers natural-language questions** using Gemini with grounded citations
- ğŸ” **Keeps data fresh** via a scheduled GitHub Actions ingestion pipeline
- ğŸŒ **Serves users via Streamlit on Cloud Run** (stateless, scalable)

---
## ğŸ’¡ Why This Matters

- USCIS Visa Bulletins are highly structured but difficult to query programmatically
- This system enables accurate, citation-backed answers without manual lookup
- The same architecture generalizes to legal, compliance, and policy documents
---

## ğŸ—ï¸ Architecture Diagram

**Important distinction**

- Ingestion pipeline â†’ automated (CI/CD) document refresh + indexing
- Query runtime â†’ user-facing retrieval + grounded answering
  
```mermaid
flowchart LR
    User["ğŸ‘¤ User<br/>(Browser)"]

    subgraph UI["ğŸ–¥ Streamlit UI (Cloud Run)"]
        App["ğŸ§© ui/app.py<br/>UI + Filters + Results"]
        Sync["â˜ï¸ GCS Sync (pull)<br/>gcs_sync.py / google-cloud-storage"]
        LocalChroma["ğŸ“¦ Local Chroma Dir<br/>(./chroma in container FS)"]
    end

    subgraph QA["ğŸ§  QA Chain (src/qa/qa_chain.py)"]
        Router["ğŸ§­ Intent Router<br/>(table_row / text)"]
        Retrieve["ğŸ” Chroma Retrieval<br/>(metadata filters + top-k)"]
        Grounded["ğŸ“ Grounded Answering<br/>Gemini + citations"]
    end

    subgraph Vertex["âœ¨ Vertex AI"]
        Emb["ğŸ§¬ text-embedding-005<br/>(Embeddings)"]
        LLM["ğŸ¤– gemini-2.0-flash<br/>(Answer generation)"]
    end

    subgraph CICD["ğŸ” CI/CD (GitHub Actions)"]
        GH["ğŸŸ¦ ingest.yml<br/>Scheduled + Manual"]
        DL["â¬‡ï¸ download_pdfs.py<br/>(Visa Bulletin PDFs)"]
        Ingest["ğŸ“„ ingest.py<br/>(V4 chunking + metadata)"]
        BuildChroma["ğŸ“¦ Build ./chroma<br/>(collection)"]
        Push["â˜ï¸ Upload to GCS<br/>(push sync)"]
    end

    subgraph Storage["ğŸª£ Google Cloud Storage"]
        GCS["ğŸ“ gs://.../uscis-visa-bulletin-rag/chroma<br/>(Chroma persisted store)"]
    end

    %% User query runtime path
    User -->|"Ask question"| App
    App -->|"If ./chroma empty: pull"| Sync
    Sync -->|"Download persisted store"| GCS
    Sync --> LocalChroma
    App --> Router
    Router --> Retrieve
    Retrieve --> LocalChroma
    Retrieve --> Grounded
    Grounded -->|"Calls LLM"| LLM
    Grounded -->|"Answer + Evidence + Retrieved chunks"| App

    %% CI/CD ingestion path
    GH --> DL --> Ingest
    Ingest -->|"Embeddings"| Emb
    Ingest --> BuildChroma
    BuildChroma --> Push --> GCS
```
---
## ğŸ—ï¸ Execution Sequence (End-to-End)
```mermaid
sequenceDiagram
    participant U as User (Browser)
    participant UI as Streamlit UI (Cloud Run)
    participant SY as GCS Sync (pull)
    participant CH as Local Chroma (./chroma)
    participant QA as QA Chain (qa_chain.py)
    participant VS as Chroma Vectorstore
    participant VX as Vertex AI Embeddings
    participant GM as Gemini (Vertex AI)

    Note over UI,SY: Startup / Cold start
    UI->>SY: If ./chroma missing/empty â†’ pull from GCS
    SY->>CH: Write persisted Chroma store locally

    U->>UI: Enter question + optional filters (month/source/category)
    UI->>QA: qa.ask(query, k, where)
    QA->>QA: detect_query_intent (table_row vs text)
    QA->>VS: similarity_search(query, filter=where + content_type)
    VS->>CH: load persisted vectors + metadata
    VS-->>QA: top-k retrieved Documents
    QA->>GM: generate grounded answer using retrieved excerpts
    GM-->>QA: answer with citations [DOC #]
    QA-->>UI: answer + retrieved snippets + metadata
    UI-->>U: Render Answer + Evidence + Expandable chunks
```

**Key Notes**
- GitHub Actions updates the vectorstore on a schedule (downloads PDFs â†’ chunks â†’ embeddings â†’ persist â†’ upload to GCS)
- Cloud Run is stateless: the container pulls Chroma from GCS when needed
- Queries use metadata filters (source, month, category) + semantic similarity
- Gemini is used only for grounded natural-language answering from retrieved excerpts (not for generating dates)

---

## ğŸ“ Project Structure
```text
uscis-visa-bulletin-rag/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ qa/
â”‚       â”œâ”€â”€ __init__.py            # Package marker
â”‚       â””â”€â”€ qa_chain.py            # QA chain: retrieval + grounding + Gemini answer
â”‚
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ app.py                     # Streamlit UI (Cloud Run ready)
â”‚                                  # â€¢ Auto-pulls Chroma from GCS on first run
â”‚                                  # â€¢ Manual â€œUpdate from GCSâ€ sync button
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_pdfs.py           # Download USCIS Visa Bulletin PDFs
â”‚   â”œâ”€â”€ ingest.py                  # Ingestion pipeline (V4 chunking â†’ embeddings â†’ Chroma)
â”‚   â””â”€â”€ gcs_sync.py                # Sync Chroma â†” GCS (push / pull)
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ingest.yml             # GitHub Actions: scheduled/manual ingestion â†’ upload Chroma to GCS
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ uscis_visa_bulletin_rag.ipynb  # Exploratory / prototyping notebook
â”‚
â”œâ”€â”€ .env.example                   # Environment variable template
â”œâ”€â”€ .gitignore                     # Ignores .env, chroma/, data/, .venv, caches, OS files
â”œâ”€â”€ .dockerignore                  # Keeps Cloud Run images lean
â”œâ”€â”€ .python-version                # Python version pin (uv / pyenv compatible)
â”‚
â”œâ”€â”€ Dockerfile                     # Cloud Run container (Streamlit on PORT=8080)
â”œâ”€â”€ pyproject.toml                 # uv project config & dependencies
â”œâ”€â”€ uv.lock                        # Fully locked, reproducible dependencies
â”œâ”€â”€ README.md                      # Project overview, architecture, setup, CI/CD, deployment
â””â”€â”€ main.py                        # (Optional) helpers / local entrypoint
```
---
## ğŸ”„ End-to-End Pipeline (From Raw PDFs to Live Q&A)

This project implements a **production-grade, cloud-native RAG pipeline** for USCIS Visa Bulletins â€” covering ingestion, vector storage, synchronization, and live querying via a web UI.

---

### 1ï¸âƒ£ Data Ingestion (Offline / CI-Driven)

**Trigger**
- Manually via GitHub Actions
- Or on a schedule (e.g., monthly bulletin updates)

**Steps**
1. **Download PDFs**
   - `scripts/download_pdfs.py` fetches official USCIS Visa Bulletin PDFs directly from the U.S. Department of State website.
2. **Parse & Chunk (V4 Strategy)**
   - PDFs are parsed and split using a **hierarchical chunking strategy**:
     - Document â†’ Section â†’ Sub-section
   - Preserves semantic structure for higher retrieval accuracy.
3. **Embedding**
   - Each chunk is embedded using **Vertex AI text embeddings** (`text-embedding-005`).
4. **Vector Store Creation**
   - Embeddings + metadata are stored in **ChromaDB** (local persist directory).

**Output**
- A fully built **Chroma vector index** containing USCIS visa bulletin knowledge.

---

### 2ï¸âƒ£ Persistence Layer (GCS as the Source of Truth)

After ingestion:
- The local Chroma directory is **synced to Google Cloud Storage (GCS)**.
- GCS acts as the **durable, centralized vector store**.

**Why GCS?**
- Cloud Run containers are **stateless**
- GCS enables:
  - Fast startup
  - Shared access across deployments
  - Zero reliance on local disks

**Tooling**
- `scripts/gcs_sync.py`
  - `push`: Upload Chroma â†’ GCS
  - `pull`: Download Chroma â† GCS

---

### 3ï¸âƒ£ Runtime Initialization (Cloud Run / Local UI)

When the UI starts (locally or on Cloud Run):

1. **Startup Check**
   - If `./chroma` does not exist:
     - Automatically **pulls the latest Chroma index from GCS**
2. **QA Chain Initialization**
   - Loads:
     - Chroma vector store
     - Retriever
     - Gemini QA chain
3. **App Ready**
   - UI becomes interactive only after the knowledge base is available

This ensures:
- `git clone â†’ run â†’ ask questions` works with **zero manual setup**

---

### 4ï¸âƒ£ Live Question Answering (Online)

**User Flow**
1. User enters a natural-language query in the Streamlit UI
2. System:
   - Retrieves top-K relevant chunks from Chroma
   - Grounds the prompt with retrieved context
   - Sends it to **Gemini (Vertex AI)** for answer generation
3. Final answer is returned with **hallucination-safe grounding**

**Optional Runtime Control**
- UI includes an **â€œUpdate from GCSâ€** button:
  - Pulls the latest Chroma index
  - Clears cached QA state
  - Re-initializes the retriever instantly

---

### 5ï¸âƒ£ CI + CD Separation of Concerns

| Layer | Responsibility |
|-----|---------------|
| GitHub Actions | Ingestion, embedding, GCS sync |
| Google Cloud Storage | Persistent vector storage |
| Cloud Run | Stateless UI + inference |
| Streamlit | User interaction |
| Vertex AI | Embeddings + LLM inference |

This clean separation mirrors **real enterprise GenAI architectures**.

---

### âœ… Why This Pipeline Matters

- Production-grade RAG (not a demo notebook)
- Stateless compute with durable storage
- CI-driven knowledge updates
- Cloud Runâ€“ready architecture
- Enterprise-scalable design pattern

This same pipeline can be reused for:
- Legal and policy documents
- Immigration or compliance workflows
- Financial filings
- Internal enterprise knowledge bases
---


## ğŸ—ï¸ Architecture Diagram (End-to-End Pipeline)

```mermaid
flowchart TB
  U["ğŸ‘¤ User<br/>(Browser)"]

  subgraph CR["â˜ï¸ Cloud Run: Streamlit UI"]
    UI["ğŸ–¥ï¸ Streamlit App<br/>(ui/app.py)"]
    QA["ğŸ§  QA Chain<br/>(src/qa/qa_chain.py)<br/>Retriever + Gemini Answering"]
    LocalChroma["ğŸ“¦ Local Chroma Dir<br/>(./chroma)<br/>ephemeral container filesystem"]
  end

  subgraph GCS["ğŸª£ Google Cloud Storage"]
    ChromaBucket["ğŸ—‚ï¸ Chroma Persisted Index<br/>gs://.../uscis-visa-bulletin-rag/chroma"]
  end

  subgraph Vertex["ğŸ§© Vertex AI"]
    Emb["ğŸ” Embeddings<br/>text-embedding-005"]
    LLM["âœ¨ Gemini LLM<br/>gemini-2.0-flash"]
  end

  subgraph GHA["ğŸ¤– GitHub Actions (CI)"]
    DL["â¬‡ï¸ Download PDFs<br/>(scripts/download_pdfs.py)"]
    ING["ğŸ§± Chunk + Embed + Persist<br/>(scripts/ingest.py)<br/>V4 hierarchical chunks"]
    SYNC_PUSH["ğŸ“¤ Sync Chroma â†’ GCS<br/>(scripts/gcs_sync.py push)"]
  end

  subgraph SRC["ğŸ“„ Source Data"]
    DOS["ğŸŒ U.S. Dept of State PDFs<br/>Visa Bulletin"]
  end

  %% CI pipeline flow
  DOS --> DL
  DL --> ING
  ING --> SYNC_PUSH
  SYNC_PUSH --> ChromaBucket
  ING --> Emb

  %% Runtime flow
  U -->|"Ask question"| UI
  UI --> QA

  %% Startup / refresh sync
  UI -->|"Auto pull if ./chroma empty<br/>or 'Update from GCS' button"| LocalChroma
  LocalChroma -->|"pull index"| ChromaBucket

  %% Retrieval + answering
  QA -->|"Similarity search"| LocalChroma
  QA -->|"Grounded prompt + context"| LLM
  UI -->|"Answer + retrieved evidence"| U
```
## ğŸ—ï¸ Execution Sequence (Runtime Q&A)
```mermaid
sequenceDiagram
  participant U as User (Browser)
  participant UI as Streamlit UI (Cloud Run)
  participant SY as GCS Sync (pull)
  participant G as GCS (Chroma Index)
  participant VS as Chroma Vectorstore (./chroma)
  participant E as Vertex AI Embeddings
  participant L as Gemini LLM (Vertex AI)

  Note over UI: On startup (or via Update button)
  UI->>SY: Pull latest Chroma index
  SY->>G: Download gs://.../chroma
  G-->>SY: Chroma files
  SY-->>UI: ./chroma updated

  U->>UI: Enter query + click Ask
  UI->>VS: similarity_search(query, k, where)
  VS-->>UI: Top-K chunks + metadata

  Note over UI: Build grounded context from chunks
  UI->>L: Prompt (rules + question + retrieved excerpts)
  L-->>UI: Grounded answer with citations

  UI-->>U: Show answer + retrieved chunks + metadata
```
---

## ğŸ› ï¸ Prerequisites

### Local Development
- **Python 3.11+** (recommended via `.python-version`)
- **[`uv`](https://github.com/astral-sh/uv)** â€“ fast Python package & environment manager
- **Git**
- **Google Cloud SDK (`gcloud`)** authenticated locally  
  ```bash
  gcloud auth application-default login
  ```
### Google Cloud Platform - A GCP project with:
- **Vertex AI API enabled**
- **loud Run enabled**
- **Cloud Build enabled**
- **Cloud Storage enabled**
- **Access to Gemini models on Vertex AI**
- **A GCS bucket for persisting Chroma vector indexes**

### GitHub (CI/CD) - A GitHub repository with:
- **GitHub Actions enabled**
- **Workload Identity Federation (WIF) configured for secure GCP access**
- **Required GitHub Secrets:**
- **GOOGLE_CLOUD_PROJECT**
- **GOOGLE_CLOUD_REGION**
- **GCP_SERVICE_ACCOUNT**
- **GCP_WIF_PROVIDER**
- **GCS_CHROMA_PATH**

### Runtime (Cloud Run)
- **A service account with:**
- **roles/storage.objectAdmin on the Chroma GCS bucket**
- **roles/aiplatform.user on the GCP project**
- **Cloud Run service configured to:**
- **Listen on PORT=8080**
- **Run in stateless mode (Chroma pulled from GCS on startup)**

---
## âš™ï¸ Setup Instructions

Follow these steps to run the **USCIS Visa Bulletin RAG** system locally.

This setup is designed so that **anyone cloning the repo can run the UI with minimal friction**, while still matching the production (Cloud Run + GCS + Vertex AI) architecture.

---

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/AvinashBolleddula/uscis-visa-bulletin-rag.git
cd uscis-visa-bulletin-rag
```

### 2ï¸âƒ£ Create and activate a virtual environment
This project uses uv for fast and reproducible Python environments.
```bash
uv venv
source .venv/bin/activate
```
You should now see (.venv) in your terminal prompt.

### 3ï¸âƒ£ Install dependencies
Install all required dependencies exactly as defined in pyproject.toml and uv.lock.
```bash
uv sync
```
### 4ï¸âƒ£ Configure environment variables
Create a .env file inside the weather/ directory:
```bash
GOOGLE_CLOUD_PROJECT=your-gcp-project-id
GOOGLE_CLOUD_REGION=us-central1

# Models
QA_LLM_MODEL=gemini-2.0-flash
EMBED_MODEL_ID=text-embedding-005

# Chroma
CHROMA_COLLECTION=visa_bulletins_v4_hierarchical
CHROMA_PERSIST_DIR=./chroma

# GCS (used for syncing vector store)
GCS_CHROMA_PATH=gs://your-bucket-name/uscis-visa-bulletin-rag/chroma
```
Note
Vertex AI uses IAM authentication, not API keys
Ensure you are authenticated locally using:
```bash
gcloud auth application-default login
```
### 5ï¸âƒ£ Optional) Ingest data locally
âš ï¸ In production, ingestion runs via GitHub Actions
You only need this step if you want to test ingestion locally.
```bash
# Download visa bulletin PDFs
uv run python scripts/download_pdfs.py --year 2025 --all

# Ingest PDFs â†’ chunks â†’ embeddings â†’ local Chroma
uv run python scripts/ingest.py \
  --data-dir data \
  --persist-dir ./chroma \
  --collection visa_bulletins_v4_hierarchical \
  --embed-model text-embedding-005 \
  --wipe
```

### 6ï¸âƒ£ Sync Chroma from GCS (recommended)
If your Chroma index already exists in GCS (recommended path):
```bash
uv run python scripts/gcs_sync.py \
  --mode pull \
  --local ./chroma \
  --gcs "$GCS_CHROMA_PATH"
```
This mirrors production behavior and avoids re-ingestion.

### Run the Streamlit UI locally
```bash
uv run streamlit run ui/app.py
```
You should see output similar to:
```bash
Local Chroma not found. Syncing from GCS...
QA system initialized successfully
```
Open your browser at:
```bash
http://localhost:8501
```

## Ask questions ğŸ¯
### Example query:

- **â€œF2A Final Action Date for Mexico November 2025â€**

### The system will:
- **1.	Retrieve relevant chunks from Chroma**
- **2.	Apply metadata filters if provided**
- **3.	Generate an answer using Gemini (Vertex AI)**
- **4.	Show citations and retrieved context**

### âœ… What You Now Have
- **Fully working local RAG system**
- **Same behavior as Cloud Run production**
- **Stateless design (safe restarts, reproducible runs)**
- **CI/CD-ready ingestion pipeline**

### You are now ready to:
- **Deploy to Cloud Run**
- **Extend to FastAPI**
- **Add auth, rate limits, or multi-tenant support ğŸš€**



